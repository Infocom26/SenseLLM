# SenseLLM
This code repository presents our unified large model for multi-task wireless sensing, SenseLLM.

## 0. Prerequisite

SenseLLM is implemented with [Python 3.8](https://www.python.org/downloads/release/python-380/) and [PyTorch 2.0.1](https://pytorch.org/get-started/previous-versions/). We manage the development environment using [Conda](https://docs.conda.io/en/latest/). Execute the following commands to configure the development environment.

- Create a conda environment called `RF-Diffusion` based on Python 3.8, and activate the environment.

```bash
conda create -n myenv python=3.8
conda activate myenv
```
- Install PyTorch, as well as other required packages.
    ```bash
    pip3 install torch
    ```
    ```bash
    pip3 install numpy scipy tensorboard tqdm matplotlib torchvision pytorch_fid
    ```

For more details about the environment configuration, refer to the `requirements.txt` file.


## 1. Train and Test


## 2. Dataset of SenseLLM
   
The training and testing datasets can be accessed via the following link: 
```bash
URL: https://pan.baidu.com/s/1Umom0eA5KV-TEG7_zJ21ZA
```
```bash
Access code: 2026
```
