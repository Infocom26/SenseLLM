# SenseLLM
This code repository presents our unified large model for multi-task wireless sensing, SenseLLM.

## 0. Prerequisite

SenseLLM is implemented with [Python 3.8](https://www.python.org/downloads/release/python-380/) and [PyTorch 2.0.1](https://pytorch.org/get-started/previous-versions/). We manage the development environment using [Conda](https://docs.conda.io/en/latest/). Execute the following commands to configure the development environment.

- Create a conda environment called `RF-Diffusion` based on Python 3.8, and activate the environment.

```bash
conda create -n myenv python=3.8
conda activate myenv
```
- Install PyTorch, as well as other required packages.
    ```bash
    pip3 install torch
    ```
    ```bash
    pip3 install numpy scipy tensorboard tqdm matplotlib torchvision pytorch_fid
    ```

For more details about the environment configuration, refer to the `requirements.txt` file in [releases](https://github.com/mobicom24/RF-Diffusion/releases/tag/dataset_model).

Download or `git clone` the `RF-Diffusion` project. Download and unzip `dataset.zip` and `model.zip` in [releases](https://github.com/mobicom24/RF-Diffusion/releases/tag/dataset_model) to the project directory.

```bash
unzip -q dataset.zip -d 'RF-Diffusion/dataset'
unzip -q model.zip -d 'RF-Diffusion'
```



## 0. Prerequisite
2. Train and Test: 
   
3. Dataset of SenseLLM:

   The training and testing datasets can be accessed via the following link:
   URL: https://pan.baidu.com/s/1Umom0eA5KV-TEG7_zJ21ZA
   Access code: 2026

4. 
